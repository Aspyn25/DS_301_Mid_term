{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (30000, 25)\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0         0         0         0                           1  \n",
      "1      1000         0      2000                           1  \n",
      "2      1000      1000      5000                           0  \n",
      "3      1100      1069      1000                           0  \n",
      "4      9000       689       679                           0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Validation Confusion Matrix:\n",
      " [[4473  200]\n",
      " [ 889  438]]\n",
      "\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      4673\n",
      "           1       0.69      0.33      0.45      1327\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.64      0.67      6000\n",
      "weighted avg       0.80      0.82      0.79      6000\n",
      "\n",
      "Validation Error Rate: 0.1815\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'trapezoid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m     area_ratio \u001b[38;5;241m=\u001b[39m area_diff \u001b[38;5;241m/\u001b[39m best_area_diff \u001b[38;5;28;01mif\u001b[39;00m best_area_diff \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m area_ratio, x, cum_defaults, D\n\u001b[0;32m--> 111\u001b[0m area_ratio_val, x_val, cum_defaults_val, D_val \u001b[38;5;241m=\u001b[39m compute_area_ratio(y_test, y_prob, use_ssm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Area Ratio (with SSM):\u001b[39m\u001b[38;5;124m\"\u001b[39m, area_ratio_val)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_lift_chart\u001b[39m(x, cum_defaults, D, N):\n",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m, in \u001b[0;36mcompute_area_ratio\u001b[0;34m(y_true, y_score, use_ssm, n)\u001b[0m\n\u001b[1;32m     98\u001b[0m D \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y_true)       \u001b[38;5;66;03m# Total defaults (using original labels)\u001b[39;00m\n\u001b[1;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m area_model \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrapezoid(cum_defaults, x)\n\u001b[1;32m    103\u001b[0m area_baseline \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m D \u001b[38;5;241m*\u001b[39m N\n\u001b[1;32m    104\u001b[0m area_diff \u001b[38;5;241m=\u001b[39m area_model \u001b[38;5;241m-\u001b[39m area_baseline\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'trapezoid'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- 1. Data and Preparation ---\n",
    "df = pd.read_csv('default_credit_score.csv', sep=',')\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "if 'ID' in df.columns:\n",
    "    df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "X = df.drop(\"default payment next month\", axis=1)\n",
    "y = df[\"default payment next month\"]\n",
    "\n",
    "# --- 2. Train-Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 3. Build the Pruned Classification Tree Module ---\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('clf', DecisionTreeClassifier(max_depth=4, min_samples_split=200,\n",
    "                                     min_samples_leaf=50, random_state=42))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- 4. Predictions and Basic Evaluation ---\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "error_rate = 1 - accuracy\n",
    "\n",
    "print(\"Validation Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nValidation Classification Report:\\n\", report)\n",
    "print(\"Validation Error Rate:\", error_rate)\n",
    "\n",
    "# --- 5. SSM Smoothing Function ---\n",
    "def smooth_ssm(y_sorted, n=50):\n",
    "    \"\"\"\n",
    "    Applies the Sorting Smoothing Method (SSM) using a moving average.\n",
    "\n",
    "    Parameters:\n",
    "        y_sorted (np.array): Sorted true labels (0 or 1) according to predicted probabilities.\n",
    "        n (int): Half window size. The full window size is 2*n+1.\n",
    "\n",
    "    Returns:\n",
    "        smoothed (np.array): Smoothed probability estimates.\n",
    "    \"\"\"\n",
    "    kernel = np.ones(2*n + 1) / (2*n + 1)\n",
    "    smoothed = np.convolve(y_sorted, kernel, mode='same')\n",
    "    return smoothed\n",
    "\n",
    "# --- 6. Compute Lift Chart and Area Ratio with SSM ---\n",
    "def compute_area_ratio(y_true, y_score, use_ssm=True, n=50):\n",
    "    \"\"\"\n",
    "    Computes the area ratio based on the lift chart.\n",
    "\n",
    "    If use_ssm is True, the true labels (ordered by predicted probability)\n",
    "    are smoothed using the Sorting Smoothing Method (SSM) with window size 2*n+1.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): True binary labels.\n",
    "        y_score (array-like): Predicted probabilities for the positive class.\n",
    "        use_ssm (bool): Whether to apply SSM smoothing.\n",
    "        n (int): Half window size for SSM (full window = 2*n+1).\n",
    "\n",
    "    Returns:\n",
    "        area_ratio (float): Ratio of (area between model curve and baseline)\n",
    "                            to (area between best curve and baseline).\n",
    "        x (np.array): x-axis values (from 0 to N).\n",
    "        cum_defaults (np.array): Cumulative defaults (model curve) starting at 0.\n",
    "        D (float): Total number of defaults in y_true.\n",
    "    \"\"\"\n",
    "    # Sort indices based on predicted probabilities (highest first)\n",
    "    sorted_indices = np.argsort(y_score)[::-1]\n",
    "    y_true_sorted = np.array(y_true)[sorted_indices].astype(float)\n",
    "\n",
    "    # Apply SSM smoothing if requested\n",
    "    if use_ssm:\n",
    "        y_smoothed = smooth_ssm(y_true_sorted, n)\n",
    "    else:\n",
    "        y_smoothed = y_true_sorted\n",
    "\n",
    "    # Compute cumulative sum starting from 0\n",
    "    cum_defaults = np.insert(np.cumsum(y_smoothed), 0, 0)\n",
    "\n",
    "    N = len(y_true)          # Total samples\n",
    "    D = np.sum(y_true)       # Total defaults (using original labels)\n",
    "    x = np.arange(0, N + 1)\n",
    "\n",
    "    area_model = np.trapezoid(cum_defaults, x)\n",
    "\n",
    "    area_baseline = 0.5 * D * N\n",
    "    area_diff = area_model - area_baseline\n",
    "\n",
    "    best_area_diff = 0.5 * D * (N - D)\n",
    "\n",
    "    area_ratio = area_diff / best_area_diff if best_area_diff != 0 else None\n",
    "    return area_ratio, x, cum_defaults, D\n",
    "\n",
    "area_ratio_val, x_val, cum_defaults_val, D_val = compute_area_ratio(y_test, y_prob, use_ssm=True, n=50)\n",
    "print(\"Validation Area Ratio (with SSM):\", area_ratio_val)\n",
    "\n",
    "def plot_lift_chart(x, cum_defaults, D, N):\n",
    "    \"\"\"\n",
    "    Plots the lift chart showing the model curve (smoothed), baseline, and best curve.\n",
    "\n",
    "    Parameters:\n",
    "        x (np.array): x-axis values (from 0 to N).\n",
    "        cum_defaults (np.array): Cumulative defaults from the model curve.\n",
    "        D (float): Total number of defaults.\n",
    "        N (int): Total number of records.\n",
    "    \"\"\"\n",
    "    baseline = (D / N) * x\n",
    "    best_curve = np.minimum(x, D)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x, cum_defaults, label='Model Curve (SSM)')\n",
    "    plt.plot(x, baseline, label='Baseline Curve', linestyle='--')\n",
    "    plt.plot(x, best_curve, label='Best Curve', linestyle='-.')\n",
    "    plt.xlabel(\"Number of Total Data\")\n",
    "    plt.ylabel(\"Cumulative Number of Defaults\")\n",
    "    plt.title(\"Lift Chart - Classification Trees (Validation, SSM)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "N_val = len(y_test)\n",
    "plot_lift_chart(x_val, cum_defaults_val, D_val, N_val)\n",
    "\n",
    "# --- 7. Evaluate Training Data with SSM ---\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_train_prob = pipeline.predict_proba(X_train)[:, 1]\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_error_rate = 1 - train_accuracy\n",
    "area_ratio_train, x_train, cum_defaults_train, D_train = compute_area_ratio(y_train, y_train_prob, use_ssm=True, n=50)\n",
    "\n",
    "print(\"Training Error Rate:\", train_error_rate)\n",
    "print(\"Training Area Ratio (with SSM):\", area_ratio_train)\n",
    "\n",
    "# --- 8. Print the Values in a Table Format ---\n",
    "results = {\n",
    "    'Method': ['Classification Trees'],\n",
    "    'Error Rate (Training)': [train_error_rate],\n",
    "    'Error Rate (Validation)': [error_rate],\n",
    "    'Area Ratio (Training)': [area_ratio_train],\n",
    "    'Area Ratio (Validation)': [area_ratio_val]\n",
    "}\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nTable 1: Classification Accuracy\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
